{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date\n",
    "from kenpompy.utils import login\n",
    "import os\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will get preseason Torvik data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scraping complete for 2015! Saved to barttorvik_2015.csv\n",
      "Data scraping complete for 2016! Saved to barttorvik_2016.csv\n",
      "Data scraping complete for 2017! Saved to barttorvik_2017.csv\n",
      "Data scraping complete for 2018! Saved to barttorvik_2018.csv\n",
      "Data scraping complete for 2019! Saved to barttorvik_2019.csv\n",
      "Data scraping complete for 2020! Saved to barttorvik_2020.csv\n",
      "Data scraping complete for 2021! Saved to barttorvik_2021.csv\n",
      "Data scraping complete for 2022! Saved to barttorvik_2022.csv\n",
      "Data scraping complete for 2023! Saved to barttorvik_2023.csv\n",
      "Data scraping complete for 2024! Saved to barttorvik_2024.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Torvik Preseason Scaper\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_barttorvik(year):\n",
    "    # URL for the given year\n",
    "    url = f\"https://barttorvik.com/trank-time-machine.php?year={year}\"\n",
    "\n",
    "    # Send GET request\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        # Locate the table\n",
    "        table = soup.find(\"table\")\n",
    "\n",
    "        if table is None:\n",
    "            print(f\"No table found for year {year}.\")\n",
    "            return\n",
    "\n",
    "        # Extract rows of the table\n",
    "        rows = table.find_all(\"tr\")[1:]  # Skip the header row\n",
    "\n",
    "        data = []\n",
    "        for row in rows:\n",
    "            cells = row.find_all(\"td\")\n",
    "            if len(cells) >= 9:  # Ensure the row has at least 9 columns\n",
    "                team = cells[1].text.strip()  # Column 2: Team\n",
    "                barthag = cells[8].text.strip()  # Column 9: BARTHAG\n",
    "\n",
    "                # Append the data\n",
    "                data.append({\"Year\": year, \"Team\": team, \"BARTHAG\": barthag})\n",
    "\n",
    "        # Save to CSV\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(f\"torvikpreseasondata/barttorvik_{year}.csv\", index=False)\n",
    "        print(f\"Data scraping complete for {year}! Saved to barttorvik_{year}.csv\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data for year {year}. HTTP Status Code: {response.status_code}\")\n",
    "\n",
    "# Loop over years from 2015 to 2024\n",
    "for year in range(2015, 2025):\n",
    "    scrape_barttorvik(year)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sportsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
